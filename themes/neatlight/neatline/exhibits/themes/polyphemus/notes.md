## A poem, typset inside its own title

I've been thinking a lot recently about weird, experimental ways to represent text documents. This actually grows out of a number of other (less weird, more useful) projects that I've had the good luck to work on in recent years, many of which, in one way or another, have turned on the question of how to take some kind of static chunk of text and find a useful and appealing way to put it on a computer screen. Sometimes I wonder if this task is one of those very high (or low) level problems that lots of other projects eventually resolve into, in one way or another. Neatline, for example, started just as a mapping project, but then we realized that we almost always wanted to _say_ something about the maps we were making, and started thinking about ways of wiring up interactive maps and text documents. It's sort of like when you're reading a computer science paper and someone says that a computational task "resolves" to this or that NP-hard problem - the specific task at hand can be boiled down to a simpler, more generalized problem, that, if solved, would cascade up to lots of

Not that it's really a "problem" with a "solution" - I think there are a bascially infinite number of ways to go about it, and we've only tried a couple of them. We've had thousands years to think about how to typeset texts on physical pages, and really just about 20 years to figure out how to do it on computer screens, depending on where you draw the lines. Usually, it's important for these projects to be usable, intuitive, legible. There's often some kind of functional goal - communicate some information, tease out some kind of insight about the text that would be hard to capture on an analog page, etc. This requirement for usability means that we usually don't really muck around that much with the really low-level mechanics of the basic reading interface. This blog post, for example, is basically interoperable with analog text - I could literally print out a physical copy in just a couple seconds, and the experience of reading it wouldn't really be different in an important way. What we're really doing, a lot of the time, is _migrating_ texts into a digital environment, not really diving into the question (possibly a rabbit hole) of how computers could be used to totally reengineer the core functionality of text documents from the ground up.

And, really, this makes a lot of sense. Analog documents work just fine (spectacularly, really), and they're put together the way they are for good reasons. The basic layout of analog documents - words/symbols/characters laid out on a one-dimensional axis, wrapped to fit onto some kind of reasonably-sized page - is probably governed by pretty low-level things - the physiology of vision, the cognitive machinery that sits behind it, the simple pragmatics of reading, etc. Having said that, I often find myself daydreaming about what kinds of totally crazy, impractical, ludic reading interfaces could be built if the requirements for usability and legibility were completely lifted. This lends itself to weird thought experiments. If I were an alien with no knowledge of books or human culture, but magically knew how to read English words and program javascript, and was dropped into the world with a laptop - how would I lay out a piece of text?

The answers tend to be weird and impractical, by definition, and they often seem most promising as some flavor of electronic literature. I was thinking about this recently, and decided to try my hand at actually building one of them. I played around with a couple of similar projects last fall, creating digital typesettings of little isolated fragments of poetry, but this time I wanted to try to do an entire work - a whole poem, a complete text that could actually be read from start to finish, instead of just kind of alluding outward to the "real" text beyond the digital environment. I decided to try it out with a little poem called Polyphemus that I've been playing with for about four years - I wrote a long version of it back in 2010, right after finishing college, rewrote it a handful of times, and eventually typed out a really short version as a block comment in the source code of Exquisite Haiku, a web application for collaborative poetry composition that I built as a 20% project back at the Scholars' Lab.

The idea was this - take the words in a poem, and physically place them inside the letter glyphs of the poem's title:

[ss]

Once all the words were in place, I realized that I wanted some way to "traverse" the poem, to slide through it, to smoothly read the entire thing without having to manually pan the display. This is ironic - really, what I wanted was to be able to read it more "normally," in a sense, which gets back to the question of just how much innovation is really desirable at the level of the basic reading mechanic. But, I decided to stick with it, because I liked something about the way the new layout of the poem jibed with the content. Or, really, the genre - in one way or another, dramatic monologues are always trying to characaterize or define the speaker, to _be_ the speaker, in a sense. Here, I realized, this gets encoded into the dimensional layout of the text - the poem is inscribed inside the name of the speaker, it literally conforms to the shape of the word that signifies the person being described.

To chip away at the problem of finding a way to add "rails" or "directionality," I added a little slider the bottom of the screen, which can either by dragged with the cursor or "stepped" forward or backward by pressing the arrow keys. Since neatline always centers the selected record exactly in the center of the screen, this results in something similar to commercial speed-reading interfaces like Spritz - you can just leave your eyes centered on the center of the screen, hold down the right arrow key, and "watch" the poem as much as read it:

[ss]

# The dream - the deep page

These projects are fun to make, but they're brittle and can't really scale much beyond this. OpenLayers does a really good job of rendering the really high-density geometries that are needed to represent the letter shapes, but the content management is slow and difficult - Neatline is a GIS client at heart, not a text editor, and the workflow leaves a lot to be desired (Polyphemus is a brisk 94 words, and I bet I spent at least 10-15 hours putting this together). Really, this is a simple attempt to prototype a much larger and more interesting project, a generalization of this type of deeply-zoomable "page" that would be much easier to create, edit, and navigate.

I'm not totally sure what this would look like, but I think the crux of it would be this - a writing and reading environment that would treat _depth_ or _zoom_ as a completely first-class dimension. I've had a vague sense that something like this would be interesting and useful for a while, but I couldn't really put a finger on exactly why. Then, a couple weeks ago, I stumbled across a fascinating paper abstract from DH2014 that surveys a number of different variations on exactly this idea, and frames it in a way that was really clarifying for me. In "The Layered Text," Florentina Armaselu traces this idea back to work by Neal Stephenson, who in turn draws from Barthes, that proposes the notion of a "z-text," a collection vertically stacked text fragments, each of which is expanded and elaborated on by the snippet that sits below it. Reading takes place on two dimensions - "forward," along the conventional textual axis, and also "down" or "into" any of the fragments that make up the text.

Poetry aside, this could be fantastically useful whenever you want to formalize any kind hierarchical relationship among different parts of a text, or create a kind of gradaded representation of complexity or detail. A footnote or annotation could sit "below" a phrase, instead of being pushed off into the margin or to the bottom of the document. Or think about the whole class of organizational techniques that we use to make it easy to engage with texts at different levels of detail or completeness. We start with a table of contents, which then feeds into something like an abstract, an introduction, an executive summary - each step providing a progressively more detailed fractal reprsentation of the structure of the document - and then finally provide the full or complete treatments of the sections. A deeply zoomed page would formalize this structure, and make it unnecessary to fall back on the "multi-pass" treatment that regular, one-dimensional documents have to rely on, which, by comparison, seems inefficient and repetitive.

From this perspective, it actually makes a lot of sense that technologies that were originally designed for mapping (Neatline, OpenLayers) turn out to be weirdly good at mocking out rickety little approximations of this idea. If you think about it, digital maps do _exactly_ this, just in a visual sense. You often start out with a broad, low-detail, zoomed-back representation of a place - say, the United States - and then progressively zoom downwards, losing the comprehensiveness of the original view but gaining enormous detail at one place or another. the z-text is exactly the same idea, just migrated to text. The question of how to build that interface in a way that's as fluid and intuitive as a slippy map is totally fascinating and, I think, unsolved.
